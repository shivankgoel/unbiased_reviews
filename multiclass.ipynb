{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Data Loaded\n",
      "Businesses Data Loaded\n",
      "Review Data Loaded\n"
     ]
    }
   ],
   "source": [
    "from helper import *\n",
    "from datasetcreator import *\n",
    "from dependencies import *\n",
    "from loaddata import review_data,business_data, rest_data, user_data, elite_udata, non_elite_udata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary:  15374\n"
     ]
    }
   ],
   "source": [
    "cv, bid_2_stars_ne, review_data_ne, bid_2_textenc = give_text_feats_tfidf(review_data)\n",
    "bid_2_stars_e = review_data.loc[review_data['iselite'] == True].groupby('business_id')['stars'].apply(list).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_multiclass(min_thold, bdata, bid_2_stars, bid_2_stars_e, bid_2_textenc, max_thold=float('inf')):\n",
    "    basicprint = False\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    bids = bdata['business_id'].values\n",
    "    for bid in bids:\n",
    "        if bid in bid_2_stars and bid in bid_2_stars_e and bid in bid_2_textenc:\n",
    "            stars_e = bid_2_stars_e[bid]\n",
    "            stars_ne = bid_2_stars[bid]\n",
    "            lestars = len(stars_e)\n",
    "            if(lestars >= min_thold and lestars < max_thold):\n",
    "                x = []\n",
    "                x.append([np.mean(stars_ne)])\n",
    "                countratings_ne = [Counter(stars_ne)[i] for i in range(1,6)]\n",
    "                distribution_ne = [x/sum(countratings_ne) for x in countratings_ne]\n",
    "                x.append(distribution_ne)\n",
    "                x.append(give_categ(np.mean(stars_ne)))\n",
    "                x.append(bid_2_textenc[bid])\n",
    "                x = [item for sublist in x for item in sublist]\n",
    "                x1.append(x)\n",
    "                countratings_e = [Counter(stars_e)[i] for i in range(1,6)]\n",
    "                distribution_e = [x/sum(countratings_e) for x in countratings_e]\n",
    "                y.append(distribution_e)                        \n",
    "    xfeat = np.array(x1)\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    xfeat = imp.fit_transform(xfeat)\n",
    "    yfeat = np.array(y)\n",
    "    print(\"Dimension of Our Dataset: \", xfeat.shape)\n",
    "    return xfeat,yfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Our Dataset:  (5926, 15421)\n"
     ]
    }
   ],
   "source": [
    "xfeat,yfeat = create_dataset_multiclass(40,business_data,bid_2_stars_ne,bid_2_stars_e,bid_2_textenc)\n",
    "xtrain, xtest, ytrain, ytest = give_train_test_multi(xfeat, yfeat)\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(xtrain) \n",
    "# xtrain = scaler.transform(xtrain)  \n",
    "# xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_multiclass(min_thold, bdata, bid_2_stars, bid_2_stars_e, bid_2_textenc, max_thold=float('inf')):\n",
    "    basicprint = False\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    bids = bdata['business_id'].values\n",
    "    for bid in bids:\n",
    "        if bid in bid_2_stars and bid in bid_2_stars_e and bid in bid_2_textenc:\n",
    "            stars_e = bid_2_stars_e[bid]\n",
    "            stars_ne = bid_2_stars[bid]\n",
    "            lestars = len(stars_e)\n",
    "            if(lestars >= min_thold and lestars < max_thold):\n",
    "                x = []\n",
    "                x.append([np.mean(stars_ne)])\n",
    "                countratings_ne = [Counter(stars_ne)[i] for i in range(1,6)]\n",
    "                distribution_ne = [x/sum(countratings_ne) for x in countratings_ne]\n",
    "                x.append(distribution_ne)\n",
    "                x.append(give_categ(np.mean(stars_ne)))\n",
    "                x.append(bid_2_textenc[bid])\n",
    "                x = [item for sublist in x for item in sublist]\n",
    "                x1.append(x)\n",
    "                countratings_e = [Counter(stars_e)[i] for i in range(1,6)]\n",
    "                distribution_e = [x/sum(countratings_e) for x in countratings_e]\n",
    "                y.append(distribution_e)                        \n",
    "    xfeat = np.array(x1)\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    xfeat = imp.fit_transform(xfeat)\n",
    "    yfeat = np.array(y)\n",
    "    print(\"Dimension of Our Dataset: \", xfeat.shape)\n",
    "    return xfeat,yfeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(50, input_dim=15421, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "opt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(loss='kullback_leibler_divergence', optimizer=opt, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4740 samples\n",
      "Epoch 1/100\n",
      "4740/4740 [==============================] - 1s 310us/sample - loss: 0.1194 - accuracy: 0.6196\n",
      "Epoch 2/100\n",
      "4740/4740 [==============================] - 1s 197us/sample - loss: 0.0797 - accuracy: 0.7013\n",
      "Epoch 3/100\n",
      "4740/4740 [==============================] - 1s 196us/sample - loss: 0.0659 - accuracy: 0.7291\n",
      "Epoch 4/100\n",
      "4740/4740 [==============================] - 1s 199us/sample - loss: 0.0607 - accuracy: 0.7346\n",
      "Epoch 5/100\n",
      "4740/4740 [==============================] - 1s 198us/sample - loss: 0.0582 - accuracy: 0.7496\n",
      "Epoch 6/100\n",
      "4740/4740 [==============================] - 1s 203us/sample - loss: 0.0565 - accuracy: 0.7549\n",
      "Epoch 7/100\n",
      "4740/4740 [==============================] - 1s 216us/sample - loss: 0.0556 - accuracy: 0.7574\n",
      "Epoch 8/100\n",
      "4740/4740 [==============================] - 1s 222us/sample - loss: 0.0545 - accuracy: 0.7624\n",
      "Epoch 9/100\n",
      "4740/4740 [==============================] - 1s 221us/sample - loss: 0.0538 - accuracy: 0.7624\n",
      "Epoch 10/100\n",
      "4740/4740 [==============================] - 1s 220us/sample - loss: 0.0529 - accuracy: 0.7686\n",
      "Epoch 11/100\n",
      "4740/4740 [==============================] - 1s 219us/sample - loss: 0.0523 - accuracy: 0.7705\n",
      "Epoch 12/100\n",
      "4740/4740 [==============================] - 1s 220us/sample - loss: 0.0520 - accuracy: 0.7722\n",
      "Epoch 13/100\n",
      "4740/4740 [==============================] - 1s 220us/sample - loss: 0.0518 - accuracy: 0.7675\n",
      "Epoch 14/100\n",
      "4740/4740 [==============================] - 1s 218us/sample - loss: 0.0513 - accuracy: 0.7730\n",
      "Epoch 15/100\n",
      "4740/4740 [==============================] - 1s 215us/sample - loss: 0.0509 - accuracy: 0.7772\n",
      "Epoch 16/100\n",
      "4740/4740 [==============================] - 1s 215us/sample - loss: 0.0506 - accuracy: 0.7730\n",
      "Epoch 17/100\n",
      "4740/4740 [==============================] - 1s 221us/sample - loss: 0.0500 - accuracy: 0.7793\n",
      "Epoch 18/100\n",
      "4740/4740 [==============================] - 1s 223us/sample - loss: 0.0498 - accuracy: 0.7755\n",
      "Epoch 19/100\n",
      "4740/4740 [==============================] - 1s 224us/sample - loss: 0.0495 - accuracy: 0.7766\n",
      "Epoch 20/100\n",
      "4740/4740 [==============================] - 1s 232us/sample - loss: 0.0491 - accuracy: 0.7806\n",
      "Epoch 21/100\n",
      "4740/4740 [==============================] - 1s 221us/sample - loss: 0.0490 - accuracy: 0.7823\n",
      "Epoch 22/100\n",
      "4740/4740 [==============================] - 1s 217us/sample - loss: 0.0487 - accuracy: 0.7749\n",
      "Epoch 23/100\n",
      "4740/4740 [==============================] - 1s 221us/sample - loss: 0.0485 - accuracy: 0.7808\n",
      "Epoch 24/100\n",
      "4740/4740 [==============================] - 1s 225us/sample - loss: 0.0482 - accuracy: 0.7819\n",
      "Epoch 25/100\n",
      "4740/4740 [==============================] - 1s 232us/sample - loss: 0.0480 - accuracy: 0.7840\n",
      "Epoch 26/100\n",
      "4740/4740 [==============================] - 1s 239us/sample - loss: 0.0482 - accuracy: 0.7838\n",
      "Epoch 27/100\n",
      "4740/4740 [==============================] - 1s 229us/sample - loss: 0.0477 - accuracy: 0.7869\n",
      "Epoch 28/100\n",
      "4740/4740 [==============================] - 1s 220us/sample - loss: 0.0475 - accuracy: 0.7835\n",
      "Epoch 29/100\n",
      "4740/4740 [==============================] - 1s 222us/sample - loss: 0.0473 - accuracy: 0.7886\n",
      "Epoch 30/100\n",
      "4740/4740 [==============================] - 1s 225us/sample - loss: 0.0473 - accuracy: 0.7848\n",
      "Epoch 31/100\n",
      "4740/4740 [==============================] - 1s 225us/sample - loss: 0.0469 - accuracy: 0.7892\n",
      "Epoch 32/100\n",
      "4740/4740 [==============================] - 1s 222us/sample - loss: 0.0469 - accuracy: 0.7897\n",
      "Epoch 33/100\n",
      "4740/4740 [==============================] - 1s 225us/sample - loss: 0.0465 - accuracy: 0.7926\n",
      "Epoch 34/100\n",
      "4740/4740 [==============================] - 1s 237us/sample - loss: 0.0465 - accuracy: 0.7890\n",
      "Epoch 35/100\n",
      "4740/4740 [==============================] - 1s 296us/sample - loss: 0.0465 - accuracy: 0.7888\n",
      "Epoch 36/100\n",
      "4740/4740 [==============================] - 1s 226us/sample - loss: 0.0464 - accuracy: 0.7895\n",
      "Epoch 37/100\n",
      "4740/4740 [==============================] - 1s 223us/sample - loss: 0.0461 - accuracy: 0.7928\n",
      "Epoch 38/100\n",
      "4740/4740 [==============================] - 1s 226us/sample - loss: 0.0462 - accuracy: 0.7905\n",
      "Epoch 39/100\n",
      "4740/4740 [==============================] - 1s 241us/sample - loss: 0.0457 - accuracy: 0.7932\n",
      "Epoch 40/100\n",
      "4740/4740 [==============================] - 1s 214us/sample - loss: 0.0462 - accuracy: 0.7882\n",
      "Epoch 41/100\n",
      "4740/4740 [==============================] - 1s 209us/sample - loss: 0.0458 - accuracy: 0.7903\n",
      "Epoch 42/100\n",
      "4740/4740 [==============================] - 1s 214us/sample - loss: 0.0455 - accuracy: 0.7865\n",
      "Epoch 43/100\n",
      "4740/4740 [==============================] - 1s 226us/sample - loss: 0.0455 - accuracy: 0.7943\n",
      "Epoch 44/100\n",
      "4740/4740 [==============================] - 1s 220us/sample - loss: 0.0455 - accuracy: 0.7916\n",
      "Epoch 45/100\n",
      "4740/4740 [==============================] - 1s 249us/sample - loss: 0.0453 - accuracy: 0.7926\n",
      "Epoch 46/100\n",
      "4740/4740 [==============================] - 1s 277us/sample - loss: 0.0453 - accuracy: 0.7941\n",
      "Epoch 47/100\n",
      "4740/4740 [==============================] - 1s 294us/sample - loss: 0.0449 - accuracy: 0.7926\n",
      "Epoch 48/100\n",
      "4740/4740 [==============================] - 1s 233us/sample - loss: 0.0448 - accuracy: 0.7928\n",
      "Epoch 49/100\n",
      "4740/4740 [==============================] - 1s 238us/sample - loss: 0.0448 - accuracy: 0.7916\n",
      "Epoch 50/100\n",
      "4740/4740 [==============================] - 1s 284us/sample - loss: 0.0450 - accuracy: 0.7949\n",
      "Epoch 51/100\n",
      "4740/4740 [==============================] - 1s 300us/sample - loss: 0.0445 - accuracy: 0.7964\n",
      "Epoch 52/100\n",
      "4740/4740 [==============================] - 2s 332us/sample - loss: 0.0450 - accuracy: 0.7945\n",
      "Epoch 53/100\n",
      "4740/4740 [==============================] - 2s 337us/sample - loss: 0.0446 - accuracy: 0.7939\n",
      "Epoch 54/100\n",
      "4740/4740 [==============================] - 1s 215us/sample - loss: 0.0442 - accuracy: 0.7966\n",
      "Epoch 55/100\n",
      "4740/4740 [==============================] - 1s 223us/sample - loss: 0.0441 - accuracy: 0.7989\n",
      "Epoch 56/100\n",
      "4740/4740 [==============================] - 1s 219us/sample - loss: 0.0439 - accuracy: 0.7992\n",
      "Epoch 57/100\n",
      "4740/4740 [==============================] - 1s 213us/sample - loss: 0.0440 - accuracy: 0.7945\n",
      "Epoch 58/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0438 - accuracy: 0.7964\n",
      "Epoch 59/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0439 - accuracy: 0.7945\n",
      "Epoch 60/100\n",
      "4740/4740 [==============================] - 1s 211us/sample - loss: 0.0437 - accuracy: 0.7962\n",
      "Epoch 61/100\n",
      "4740/4740 [==============================] - 1s 212us/sample - loss: 0.0437 - accuracy: 0.7941\n",
      "Epoch 62/100\n",
      "4740/4740 [==============================] - 1s 218us/sample - loss: 0.0436 - accuracy: 0.7994\n",
      "Epoch 63/100\n",
      "4740/4740 [==============================] - 1s 217us/sample - loss: 0.0435 - accuracy: 0.7968\n",
      "Epoch 64/100\n",
      "4740/4740 [==============================] - 1s 230us/sample - loss: 0.0435 - accuracy: 0.7962\n",
      "Epoch 65/100\n",
      "4740/4740 [==============================] - 1s 210us/sample - loss: 0.0432 - accuracy: 0.7987\n",
      "Epoch 66/100\n",
      "4740/4740 [==============================] - 1s 216us/sample - loss: 0.0433 - accuracy: 0.7966\n",
      "Epoch 67/100\n",
      "4740/4740 [==============================] - 1s 216us/sample - loss: 0.0433 - accuracy: 0.8013\n",
      "Epoch 68/100\n",
      "4740/4740 [==============================] - 1s 215us/sample - loss: 0.0431 - accuracy: 0.8023\n",
      "Epoch 69/100\n",
      "4740/4740 [==============================] - 1s 213us/sample - loss: 0.0432 - accuracy: 0.8019\n",
      "Epoch 70/100\n",
      "4740/4740 [==============================] - 1s 212us/sample - loss: 0.0429 - accuracy: 0.8015\n",
      "Epoch 71/100\n",
      "4740/4740 [==============================] - 1s 207us/sample - loss: 0.0433 - accuracy: 0.7951\n",
      "Epoch 72/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0428 - accuracy: 0.8017\n",
      "Epoch 73/100\n",
      "4740/4740 [==============================] - 1s 213us/sample - loss: 0.0425 - accuracy: 0.8023\n",
      "Epoch 74/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0429 - accuracy: 0.8023\n",
      "Epoch 75/100\n",
      "4740/4740 [==============================] - 1s 211us/sample - loss: 0.0427 - accuracy: 0.7964\n",
      "Epoch 76/100\n",
      "4740/4740 [==============================] - 1s 214us/sample - loss: 0.0429 - accuracy: 0.8046\n",
      "Epoch 77/100\n",
      "4740/4740 [==============================] - 1s 211us/sample - loss: 0.0426 - accuracy: 0.8053\n",
      "Epoch 78/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0425 - accuracy: 0.8061\n",
      "Epoch 79/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0422 - accuracy: 0.8021\n",
      "Epoch 80/100\n",
      "4740/4740 [==============================] - 1s 211us/sample - loss: 0.0422 - accuracy: 0.8036\n",
      "Epoch 81/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0423 - accuracy: 0.8044\n",
      "Epoch 82/100\n",
      "4740/4740 [==============================] - 1s 213us/sample - loss: 0.0417 - accuracy: 0.8095\n",
      "Epoch 83/100\n",
      "4740/4740 [==============================] - 1s 214us/sample - loss: 0.0418 - accuracy: 0.8051\n",
      "Epoch 84/100\n",
      "4740/4740 [==============================] - 1s 210us/sample - loss: 0.0425 - accuracy: 0.8057\n",
      "Epoch 85/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0419 - accuracy: 0.8040\n",
      "Epoch 86/100\n",
      "4740/4740 [==============================] - 1s 207us/sample - loss: 0.0419 - accuracy: 0.8051\n",
      "Epoch 87/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0417 - accuracy: 0.8110\n",
      "Epoch 88/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0416 - accuracy: 0.8074\n",
      "Epoch 89/100\n",
      "4740/4740 [==============================] - 1s 214us/sample - loss: 0.0416 - accuracy: 0.8086\n",
      "Epoch 90/100\n",
      "4740/4740 [==============================] - 1s 215us/sample - loss: 0.0417 - accuracy: 0.8036\n",
      "Epoch 91/100\n",
      "4740/4740 [==============================] - 1s 210us/sample - loss: 0.0420 - accuracy: 0.8027\n",
      "Epoch 92/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0413 - accuracy: 0.8084\n",
      "Epoch 93/100\n",
      "4740/4740 [==============================] - 1s 209us/sample - loss: 0.0414 - accuracy: 0.8076\n",
      "Epoch 94/100\n",
      "4740/4740 [==============================] - 1s 207us/sample - loss: 0.0416 - accuracy: 0.8070\n",
      "Epoch 95/100\n",
      "4740/4740 [==============================] - 1s 212us/sample - loss: 0.0419 - accuracy: 0.8076\n",
      "Epoch 96/100\n",
      "4740/4740 [==============================] - 1s 214us/sample - loss: 0.0412 - accuracy: 0.8105\n",
      "Epoch 97/100\n",
      "4740/4740 [==============================] - 1s 214us/sample - loss: 0.0412 - accuracy: 0.8099\n",
      "Epoch 98/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0410 - accuracy: 0.8110\n",
      "Epoch 99/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0412 - accuracy: 0.8143\n",
      "Epoch 100/100\n",
      "4740/4740 [==============================] - 1s 208us/sample - loss: 0.0410 - accuracy: 0.8076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "xtrain_scaled = scaler.fit_transform(xtrain)\n",
    "xtest_scaled = scaler.transform(xtest)\n",
    "history = model.fit(xtrain, ytrain, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytestpred = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = [x[0]*1+x[1]*2+x[2]*3+x[3]*4+x[4]*5 for x in ytestpred] \n",
    "y2 = [x[0]*1+x[1]*2+x[2]*3+x[3]*4+x[4]*5 for x in ytest] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  0.027\n",
      "R-Squared :  0.8465\n",
      "Margin  0.10  0.20  0.30  0.40  0.50\n",
      "        49.16  79.43  93.59  97.47  99.16\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8464532623070217"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_prediction(np.array(y1),np.array(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01220664, 0.03433712, 0.12517762, 0.44543287, 0.38284573],\n",
       "       [0.02541594, 0.07397583, 0.18636912, 0.4056808 , 0.3085583 ],\n",
       "       [0.01212482, 0.04916609, 0.17726123, 0.45290557, 0.30854228],\n",
       "       ...,\n",
       "       [0.01336025, 0.03853995, 0.14366622, 0.4707299 , 0.3337036 ],\n",
       "       [0.0133213 , 0.04974233, 0.18091749, 0.42772612, 0.3282928 ],\n",
       "       [0.00818162, 0.02923386, 0.13595237, 0.48767376, 0.3389584 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytestpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
